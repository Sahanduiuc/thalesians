{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import talk.config as con\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "con.config_mosek()\n",
    "con.config_configManager()\n",
    "con.config_matplotlib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Constructing estimators \n",
    "------------------------\n",
    "https://en.wikipedia.org/wiki/Autoregressive_model\n",
    "\n",
    "#### Thomas Schmelzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A very common estimator is based on AR models (autoregressive)\n",
    "\n",
    "$$R_T = \\sum_{i=1}^n w_i r_{T-i}$$\n",
    "\n",
    "Predict the (unknown) return $R_T$ using the last $n$ previous returns. **Attention**: You may want to use volatility adjusted returns, apply filters etc.\n",
    " \n",
    "How to pick the $n$ free parameters in $\\mathbf{w}$? (Partial) autocorrelations? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution(ts, weights):\n",
    "    from statsmodels.tsa.filters.filtertools import convolution_filter\n",
    "    return convolution_filter(ts, weights, nsides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "r = pd.Series([1.0, -2.0, 1.0, 1.0, 1.5, 0.0, 2.0])\n",
    "weights = [2.0, 1.0]\n",
    "# trendfollowing == positive weights\n",
    "x=pd.DataFrame()\n",
    "x[\"r\"] = r\n",
    "x[\"pred\"] = convolution(r, weights)\n",
    "x[\"before\"] = x[\"pred\"].shift(1)\n",
    "print(x)\n",
    "print(x.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# mean-reversion == negative weights\n",
    "r = pd.Series([1.0, -2.0, 1.0, 1.0, 1.5, 0.0, 2.0])\n",
    "weights = [-2.0, -1.0]\n",
    "x=pd.DataFrame()\n",
    "x[\"r\"] = r\n",
    "x[\"pred\"] = convolution(r, weights)\n",
    "x[\"before\"] = x[\"pred\"].shift(1)\n",
    "print(x)\n",
    "print(x.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Looking only at the last two returns might be a bit ...\n",
    "\n",
    "Is it a good idea to have $n=200$ free parameters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.tsa.stattools as sts\n",
    "# generate random returns\n",
    "import pandas as pd\n",
    "r = pd.read_csv(\"SPX_Index.csv\", squeeze=True, index_col=0, parse_dates=True).pct_change().dropna()\n",
    "# let's compute the optimal convolution!\n",
    "weights = sts.pacf(r, nlags=200)\n",
    "pd.Series(data=weights[1:]).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The trading system! \n",
    "pos = convolution(r, weights[1:])\n",
    "pos = 1e6*(pos/pos.std())\n",
    "# profit = return[today] * position[yesterday]\n",
    "(r*pos.shift(1)).cumsum().plot()\n",
    "plt.xlabel('Time'), plt.ylabel('Profit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias\n",
    "----\n",
    "\n",
    "We assume the weights are exponentially decaying, e.g.\n",
    "\n",
    "$$w_i = \\frac{1}{S}\\lambda^i$$\n",
    "\n",
    "where $S$ is a suitable scaling constant and $\\lambda = 1-1/N$. Note that $N \\neq n$.\n",
    "\n",
    "**Everything** that is **not** an exponentially weighted moving average is **wrong**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def exp_weights(m, n=100):\n",
    "    x = np.power(1.0 - 1.0/m, range(1,n+1))\n",
    "    S = np.linalg.norm(x)\n",
    "    return x/S\n",
    "\n",
    "pd.Series(exp_weights(m=16,n=40)).plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "periods = [2,4,6,8,12,16,24,32,48,64,96,192]\n",
    "# matrix of weights\n",
    "W = pd.DataFrame({period : exp_weights(m=period, n=200) for period in periods}) \n",
    "W.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# each column of A is a convoluted return time series\n",
    "A = pd.DataFrame({period : convolution(r, W[period]).shift(1) for period in periods})  \n",
    "\n",
    "A = A.dropna(axis=0)\n",
    "r = r[A.index].dropna()\n",
    "\n",
    "A.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(Naive) regression\n",
    "-------------------\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{w}^{*}=\\arg\\min_{\\mathbf{w} \\in \\mathbb{R}^m}& \\rVert{\\mathbf{A}\\mathbf{w} - \\mathbf{r}}\\lVert_2 \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import lstsq\n",
    "# sometimes you don't need to use MOSEK :-)\n",
    "weights = pd.Series(index=periods, data=lstsq(A.values, r.values)[0])\n",
    "print(weights)\n",
    "(W*weights).sum(axis=1).plot(kind=\"bar\")\n",
    "(W*weights).sum(axis=1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean variation\n",
    "\n",
    "We provide a few indicators. Avoid fast indicators. Prefer slower indicators as they induce less trading costs.\n",
    "Use the mean variation of the signal (convoluted returns here)\n",
    "\n",
    "$$f(\\mathbf{x}) = \\frac{1}{n}\\sum{\\lvert x_i - x_{i-1}\\rvert}=\\frac{1}{n}\\rVert{\\Delta \\mathbf{x}}\\lVert_1$$\n",
    "\n",
    "The $i$th column of $\\mathbf{A}$ has a mean variation $d_i$. We introduce the diagonal penalty matrix $\\mathbf{D}$ with $D_{i,i}=d_i$.\n",
    "\n",
    "$$\\mathbf{w}^{*}=\\arg\\min_{\\mathbf{w} \\in \\mathbb{R}^m} \\lVert{\\mathbf{Aw}-\\mathbf{r}}\\rVert_2 + \\lambda \\rVert{\\mathbf{Dw}}\\lVert_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def mean_variation(ts):\n",
    "    return ts.diff().abs().mean()\n",
    "\n",
    "d = A.apply(mean_variation)\n",
    "D = np.diag(d)\n",
    "    \n",
    "from mosek.fusion import *\n",
    "# but you could use Mosek: \n",
    "def __two_norm(model, v):\n",
    "    # add variable to model for the 2-norm of the residual\n",
    "    x = model.variable(1, Domain.greaterThan(0.0))\n",
    "    # add the quadratic cone\n",
    "    model.constraint(Expr.vstack(x,v), Domain.inQCone())\n",
    "    return x\n",
    "\n",
    "\n",
    "def __one_norm(model, v):\n",
    "    t = model.variable(int(v.size()), Domain.greaterThan(0.0))\n",
    "    model.constraint(Expr.hstack(t, v), Domain.inQCone(int(v.size()), 2))\n",
    "    return Expr.sum(t)\n",
    "\n",
    "\n",
    "def ar(A, D, r, lamb=0.0):\n",
    "\n",
    "    with Model('lasso') as model:\n",
    "        n = int(A.shape[1])\n",
    "        # introduce the variable for the var\n",
    "        x = model.variable(\"x\", n, Domain.unbounded())\n",
    "        # minimization of the conditional value at risk\n",
    "        a1 = __two_norm(model, Expr.sub(Expr.mul(DenseMatrix(A),x), Expr.constTerm(r)))\n",
    "        a2 = __one_norm(model, Expr.mul(DenseMatrix(D),x))\n",
    "        \n",
    "        model.objective(ObjectiveSense.Minimize, Expr.add(a1, Expr.mul(a2, float(lamb))))\n",
    "        model.solve()\n",
    "\n",
    "        return x.level()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "t_weight = dict()\n",
    "for lamb in [0.0, 1.0, 2.0, 3.0, 5.0, 7.0, 9.0, 12.0, 15.0]:\n",
    "    weights = pd.Series(index=periods, data=ar(A.values, D, r.values, lamb=lamb))\n",
    "    print(weights.transpose())\n",
    "    t_weight[lamb] = (W*weights).sum(axis=1)\n",
    "    t_weight[lamb].plot(kind=\"bar\")\n",
    "    t_weight[lamb].plot()\n",
    "    plt.title(lamb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for lamb in sorted(t_weight.keys()):\n",
    "    pos = convolution(r, t_weight[lamb])\n",
    "    pos = 1e6*(pos/pos.std())\n",
    "    (r*pos.shift(1)).cumsum().plot()\n",
    "    plt.title(lamb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "d = A.apply(mean_variation)\n",
    "D = np.diag(d)\n",
    "weights = pd.Series(index=periods, data=ar(A.values, D, r.values, lamb=3.0))\n",
    "print(weights)\n",
    "# let's make the first two moving averages really expensive!\n",
    "\n",
    "d = A.apply(mean_variation)\n",
    "D = np.diag(d)\n",
    "D[0,0] = 100*D[0,0]\n",
    "D[1,1] = 100*D[1,1]\n",
    "a = pd.Series(index=periods, data=ar(A.values, D, r.values, lamb=3.0))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- The problem of constructing an estimator is corresponds to tracking an index. The index is here a historic return time series. The **assets** are standard estimators. \n",
    "\n",
    "\n",
    "- Using the (mean) total variation of the signals can help to prefer slower signals rather than expensive fast signals.\n",
    "\n",
    "\n",
    "- Using a penalty induced by the $1$-norm (see LARS, LASSO) it is possible to establish a ranking amongst the indicators and construct them robustly. \n",
    "\n",
    "\n",
    "- It is possible to (vertical) stack the resulting systems to find optimal weights across a group of assets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=http://localhost:8888>Back to Overview</a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
